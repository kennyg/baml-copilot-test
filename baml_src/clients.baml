// GitHub Copilot clients via LiteLLM proxy
// Auto-generated by generate_clients.py - do not edit manually
// Regenerate with: mise run discover

client<llm> CopilotGpt4O {
  provider "openai-generic"
  options {
    base_url "http://localhost:4000/v1"
    model "gpt-4o"
    api_key env.LITELLM_API_KEY
  }
}

// Default client - uses primary model (gpt-4o)
client<llm> CopilotDefault {
  provider "openai-generic"
  options {
    base_url "http://localhost:4000/v1"
    model "gpt-4o"
    api_key env.LITELLM_API_KEY
  }
}

